{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n",
      "[5 0 4 ..., 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print train_images.shape\n",
    "print len(train_labels)\n",
    "print train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print train_images.ndim\n",
    "print train_images.dtype\n",
    "print train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRF+IKj/AWrTQ8hNqS7JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b444950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "10000\n",
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print test_images.shape\n",
    "print len(test_labels)\n",
    "print test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "2\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.01176471\n",
      "  0.07058824  0.07058824  0.07058824  0.49411765  0.53333336  0.68627453\n",
      "  0.10196079  0.65098041  1.          0.96862745  0.49803922  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.11764706  0.14117648  0.36862746\n",
      "  0.60392159  0.66666669  0.99215686  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.88235295  0.67450982  0.99215686  0.94901961  0.7647059\n",
      "  0.25098041  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.19215687\n",
      "  0.93333334  0.99215686  0.99215686  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.99215686  0.98431373  0.36470589  0.32156864\n",
      "  0.32156864  0.21960784  0.15294118  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.07058824  0.85882354  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.7764706   0.71372551  0.96862745  0.94509804\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.3137255   0.61176473\n",
      "  0.41960785  0.99215686  0.99215686  0.80392158  0.04313726  0.\n",
      "  0.16862746  0.60392159  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.05490196  0.00392157  0.60392159  0.99215686  0.35294119  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.54509807  0.99215686  0.74509805  0.00784314\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.04313726  0.74509805  0.99215686\n",
      "  0.27450982  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.13725491\n",
      "  0.94509804  0.88235295  0.627451    0.42352942  0.00392157  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.31764707  0.94117647  0.99215686  0.99215686  0.46666667  0.09803922\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.17647059  0.72941178  0.99215686  0.99215686\n",
      "  0.58823532  0.10588235  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.0627451   0.36470589\n",
      "  0.98823529  0.99215686  0.73333335  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.97647059  0.99215686  0.97647059  0.25098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.18039216  0.50980395\n",
      "  0.71764708  0.99215686  0.99215686  0.81176472  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.15294118  0.58039218  0.89803922\n",
      "  0.99215686  0.99215686  0.99215686  0.98039216  0.71372551  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.09411765  0.44705883  0.86666667  0.99215686\n",
      "  0.99215686  0.99215686  0.99215686  0.78823531  0.30588236  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.09019608  0.25882354  0.83529413  0.99215686  0.99215686\n",
      "  0.99215686  0.99215686  0.7764706   0.31764707  0.00784314  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.07058824  0.67058825  0.85882354  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.7647059   0.3137255   0.03529412  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.21568628  0.67450982  0.88627452  0.99215686  0.99215686  0.99215686\n",
      "  0.99215686  0.95686275  0.52156866  0.04313726  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.53333336  0.99215686  0.99215686  0.99215686  0.83137256\n",
      "  0.52941179  0.51764709  0.0627451   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print train_images.shape\n",
    "print train_images.ndim\n",
    "print train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preparing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.2601 - acc: 0.9245     \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.1050 - acc: 0.9687     \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0697 - acc: 0.9787     \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0499 - acc: 0.9848     \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s - loss: 0.0377 - acc: 0.9891     \n"
     ]
    }
   ],
   "source": [
    "history = network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8416/10000 [========================>.....] - ETA: 0s\n",
      "test_acc: 0.9784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print '\\ntest_acc:', test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
